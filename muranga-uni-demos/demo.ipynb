{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-customvision in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: msrest>=0.5.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from azure-cognitiveservices-vision-customvision) (1.1.28)\n",
      "Requirement already satisfied: azure-core>=1.24.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (1.26.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (2022.12.7)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (2.28.2)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (0.6.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-customvision) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests) (1.26.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (0.27.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\bethanycheum\\desktop\\muranga uni\\.venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-vision-customvision\n",
    "%pip install python-dotenv\n",
    "%pip install requests\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: metal\n",
      "Probability: 43.08%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import requests, os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Replace with your endpoint and prediction key\n",
    "ENDPOINT = os.environ['ENDPOINT']\n",
    "PREDICTION_KEY = os.environ['PREDICTION_KEY']\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "ITERATION_NAME = os.environ['ITERATION_NAME']\n",
    "\n",
    "# Authenticate with the Custom Vision API\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, credentials)\n",
    "\n",
    "# Replace with the URL of your image\n",
    "image_url = str(input(\"Enter the URL of your image: \"))\n",
    "\n",
    "# Use the Custom Vision API to predict the image\n",
    "results = predictor.classify_image_url(PROJECT_ID, ITERATION_NAME, url=image_url)\n",
    "\n",
    "# Print the predicted class and its probability\n",
    "most_likely_prediction = results.predictions[0]\n",
    "print(f\"Predicted class: {most_likely_prediction.tag_name}\")\n",
    "print(f\"Probability: {most_likely_prediction.probability:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set your API endpoint, subscription key, and image URL\n",
    "# https://muranga-demi.cognitiveservices.azure.com/\n",
    "endpoint = os.environ['endpoint']\n",
    "subscription_key = os.environ['subscription_key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "image_url = str(input(\"Enter the URL of the image you want to analyze: \"))\n",
    "\n",
    "# Set the API URL for analyzing image colors\n",
    "vision_analyze_url = endpoint + 'vision/v3.2/analyze'\n",
    "\n",
    "# Set the parameters for the API request\n",
    "params = {'visualFeatures': 'Color'}\n",
    "\n",
    "# Set the headers for the API request\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "           'Content-Type': 'application/json'}\n",
    "\n",
    "# Set the request body for the API request\n",
    "data = {'url': image_url}\n",
    "\n",
    "# Send the API request and get the response\n",
    "response = requests.post(vision_analyze_url, headers=headers, params=params, json=data)\n",
    "\n",
    "# Parse the response and extract the colors\n",
    "response_json = json.loads(response.content)\n",
    "colors = response_json['color']['dominantColors']\n",
    "\n",
    "# Print the colors\n",
    "print('Dominant colors in the image:', ', '.join(colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending a test completion job\n",
      "what is prompt engineering? - There is no definitive answer to this question, as the term prompt engineering can be interpreted in a variety of ways. Generally speaking, prompt engineering refers to the process of designing and building systems or components in a quick and efficient manner, often in response to an urgent need or requirement. This can include developing custom-made or improvised solutions to a problem, as well as using off-the-shelf components to speed up the construction process.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ['key']\n",
    "openai.api_base =  os.environ['base'] # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_type = os.environ['type']\n",
    "openai.api_version = os.environ['version'] # this may change in the future\n",
    "deployment_name = os.environ['deployment_name'] \n",
    "\n",
    "# Send a completion call to generate an answer\n",
    "print('Sending a test completion job')\n",
    "start_phrase = str(input(\"How can I help you today?:  \"))\n",
    "response = openai.Completion.create(engine=deployment_name, prompt=start_phrase, max_tokens=100)\n",
    "text = response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip()\n",
    "print(start_phrase + \" - \" +text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
